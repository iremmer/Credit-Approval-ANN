{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install pandas\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Activation\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(matrix, multiplier):\n",
    "    \"\"\"\n",
    "    Normalize the input matrix to a range between 0 and `multiplier`.\n",
    "    \n",
    "    Args:\n",
    "    - matrix: a NumPy array\n",
    "    - multiplier: the maximum value of the normalized matrix\n",
    "    \n",
    "    Returns:\n",
    "    - The normalized matrix as a NumPy array.\n",
    "    \"\"\"\n",
    "    \n",
    "    for i in range(matrix.shape[1]):\n",
    "        # Find the maximum and minimum values in the vector\n",
    "        column_max = np.max(matrix[:, i])\n",
    "        column_min = np.min(matrix[:, i])\n",
    "        \n",
    "        # Compute the range of the vector, taking care to handle the case where max = min\n",
    "        vector_range = 1 if column_max == column_min else column_max - column_min\n",
    "        \n",
    "        # Normalize the vector to a range between 0 and `multiplier`\n",
    "        matrix[:, i] = (matrix[:, i] - column_min) / (vector_range) * multiplier\n",
    "        \n",
    "        # Return the normalized vector\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_set = {'A1': [], 'A2': [], 'A3': [], 'A4': [], 'A5': [], 'A6': [], 'A7': [], 'A8': [], 'A9': [], 'A10': [], 'A11': [], 'A12': [], 'A13': [], 'A14': [], 'A15': []}\n",
    "continuous = {'A2', 'A3', 'A8', 'A11', 'A14', 'A15'}\n",
    "categoricals = ['A1', 'A4', 'A5', 'A6', 'A7', 'A9', 'A10', 'A12', 'A13']\n",
    "\n",
    "with open('crx.data', 'r') as data_file:\n",
    "    lines = data_file.readlines()\n",
    "data_file.close()\n",
    "\n",
    "labels = []\n",
    "attributes = list(categorical_set.keys())\n",
    "previous_line = ['a', '64.08', '0.165', 'u', 'g', 'ff', 'ff', '0', 't', 't', '01', 'f', 'g', '00232', '100']\n",
    "for line in lines:\n",
    "    record = line[:-1].split(',')\n",
    "\n",
    "    no_question_marks = 0\n",
    "    for i in range(len(attributes)):\n",
    "        key = attributes[i]\n",
    "        value = record[i]\n",
    "\n",
    "        if value == '?':\n",
    "            value = previous_line[i]\n",
    "            no_question_marks += 1\n",
    "\n",
    "        value = -np.float32(value) if key in continuous else value\n",
    "\n",
    "        categorical_set[key].append(value)\n",
    "\n",
    "    labels.append(1) if record[-1] == '+' else labels.append(0)\n",
    "    previous_line = record if no_question_marks == 0 else previous_line\n",
    "\n",
    "data = pd.DataFrame(categorical_set)\n",
    "encoded_data = pd.get_dummies(data, categoricals)\n",
    "\n",
    "encoded_columns = encoded_data.columns\n",
    "\n",
    "encoded_data = normalize(encoded_data.to_numpy(), 1)\n",
    "encoded_data = pd.DataFrame(encoded_data)\n",
    "encoded_data.columns = encoded_columns\n",
    "\n",
    "\n",
    "labels = pd.DataFrame(labels)\n",
    "\n",
    "\n",
    "encoded_data.to_csv('samples.csv', index=False)\n",
    "labels.to_csv('labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data = pd.read_csv('samples.csv')\n",
    "labels = pd.read_csv('labels.csv')\n",
    "random.seed(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(encoded_data, labels, test_size=0.2, random_state=2164)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "10/10 [==============================] - 1s 7ms/step - loss: 0.4883 - accuracy: 0.7953\n",
      "Epoch 2/7\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3357 - accuracy: 0.8786\n",
      "Epoch 3/7\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3251 - accuracy: 0.8678\n",
      "Epoch 4/7\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.2873 - accuracy: 0.8967\n",
      "Epoch 5/7\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.3035 - accuracy: 0.8895\n",
      "Epoch 6/7\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.2713 - accuracy: 0.8986\n",
      "Epoch 7/7\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.2622 - accuracy: 0.8986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21c12fb1ae0>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(1024, activation='relu'),\n",
    "    \n",
    "    Dense(256, activation='relu'),\n",
    "\n",
    "    Dense(128, activation='relu'),\n",
    "\n",
    "    Dense(32, activation='relu'),\n",
    "\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(x_train, y_train, epochs=7, batch_size=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss, test acc: [0.42948025465011597, 0.8550724387168884]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test, y_test, verbose = 0)\n",
    "print('test loss, test acc:', results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
